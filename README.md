# Software and data

## Warning

In most of our code we used pickle.
We later noticed we could have used torch.save() and torch.load() instead,
which is more trustworthy and avoids trouble with different devices.
We still submit the code with pickle for consistency with the data we saved.
We plan to make it compatible with both in a later version.

We do not submit any of the actual pickle data.
So feel free to change your local version of the code.

## Structure

* ```wcos_casestudies```: Code for most experiments
  * ```utils.py``` and ```plotting.py``` contain helper functions
  * ```main.py```: Run this to reproduce Section 5. There are options for each sub-experiment (see the argparse part of the code).
  * ```casestudies.py```: If you open this in VS Code, you will be able to run it cell by cell like a Jupyter notebook. It first generates the data for Appendix E (IO classes vs. functional roles), then selects the neurons for the case studies of Section 6 and does the weight-based part of the case studies.
  * ```selected_plot.py```: reproduce Figure 5 (selected layers of Llama).
  * ```defplot.py```: reproduce Figure 2 (definition plot).
* ```neuroscope```: Code for the activation-based neuron analyses in Section 6. Be aware that it takes more than a day to run it.
  * ```a_dataset.py```: Take a subset of Dolma and tokenize it.
  * ```b_activations.py```: Run the model on that dataset and store some metadata about each neuron, including the dataset indices of its largest activations.
  * ```d_recompute_vis.py```: For each neuron from the given set, create a nice HTML file that shows its activations on the max/min dataset examples.
  * ```b2_recompute``` and ```c_neuron_vis```: helper functions.
* **In the separate zip:**```results```: data generated by the ```neuroscope``` code.
  * Each subdirectory represents a layer
    * Each subdirectory thereof represents a neuron
      * Open the ```vis.html``` in a browser (or VS code with an appropriate extension). Requires JavaScript.
* ```interactive.ipynb```: interactive vector visualisations of IO classes.

## Steps to reproduce

### Environment

I use a fork of TransformerLens that supports OLMo
(acknowledgements to a colleague of ours):
https://anonymous.4open.science/r/TransformerLens-0EA4/

First, create your environment and install requirements:

```[bash]
conda create -n wcos python==3.12.4
conda activate wcos
pip install -r requirements.txt
```

Possibly in a different directory,
but with ```wcos``` still activated:

```[bash]
git clone https://anonymous.4open.science/r/TransformerLens-0EA4
cd TransformerLens
pip install -e .
```

### Section 5 (IO functionalities by layer)

```[bash]
cd wcos_casestudies
python main.py --categories --category_stats --quartiles --plot_fine --plot_coarse --plot_quartiles --plot_all_medians --model all
```

or any subset of these options / specific model names.

### Section 6 (Case studies)

#### Appendix E: IO classes vs. functional roles

For our case studies we limit the search space to prediction neurons,
so we first need to find out which these are.

Open ```casestudies.py``` in VS Code.
You will be able to run it cell by cell like a Jupyter Notebook.

#### Choosing neurons

Continue running the same script.

#### Weight-based part of the case studies

Final cell of the same script.

#### Activation-based part

You *could* run the code in ```neuroscope``` but that takes more than a day.
Instead, the ```results``` directory contains an HTML file for each of the neurons.
Open it in a browser (with JavaScript) or in VSCode if you have an appropriate extension.

**If** you want to reproduce the run, do the following steps:

```[bash]
cd ../neuroscope
python a_dataset.py --datadir YOUR_DATA_DIR --save_to dolma_small
python b_activations.py --model allenai/OLMo-7B-0424-hf --datadir YOUR_DATA_DIR --save_to results
python d_recompute_vis.py --model allenai/OLMo-7B-0424-hf --datadir YOUR_DATA_DIR --save_to results --neurons 28.4737 28.9766 31.9634 29.10900 30.10972 29.4180
```

Explanations:

* ```a_dataset.py```: Take a subset of Dolma and tokenize it.
* ```b_activations.py```: Run model on data and store some metadata about each neuron, including the dataset indices of its largest activations.
* ```d_recompute_vis.py```: For each neuron from the given set, create a nice HTML file that shows its activations on the max/min dataset examples.
